#!/usr/bin/env python3
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "pathspec>=0.12",
#     "tiktoken>=0.7.0",
# ]
# ///

import argparse
import hashlib
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, Union

try:
    import pathspec
except Exception as e:  # pathspec not installed, but uv will install automatically
    print(f"Error importing pathspec: {e}", file=sys.stderr)
    raise

try:
    import tiktoken
except Exception as e:  # tiktoken not installed, but uv will install automatically
    print(f"Error importing tiktoken: {e}", file=sys.stderr)
    raise


def setup_tiktoken_cache() -> None:
    """Set up tiktoken cache directory to avoid SSL issues."""
    # Set cache directory to user's home .cache folder
    cache_dir = Path.home() / ".cache" / "tiktoken"
    cache_dir.mkdir(parents=True, exist_ok=True)
    os.environ["TIKTOKEN_CACHE_DIR"] = str(cache_dir)
    
    # Pre-compute cache key for cl100k_base
    blobpath = "https://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken"
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
    cache_file = cache_dir / cache_key
    
    # If cache file exists, we're good
    if cache_file.exists():
        return
    
    # Try to download with fallback
    try:
        import urllib.request
        import ssl
        # Create an SSL context that doesn't verify certificates (for corporate environments)
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        with urllib.request.urlopen(blobpath, context=ssl_context) as response:
            cache_file.write_bytes(response.read())
    except Exception:
        # If download fails, we'll just proceed without token counting
        pass


def count_tokens(text: str) -> int:
    """Count tokens in text using tiktoken with cl100k_base encoding."""
    try:
        # Set up cache before trying to get encoding
        setup_tiktoken_cache()
        
        # Try to get the encoding
        encoding = tiktoken.get_encoding("cl100k_base")
        return len(encoding.encode(text))
    except Exception as e:
        # If token counting fails, just return 0 and warn
        print(f"Warning: Could not count tokens: {e}", file=sys.stderr)
        return 0


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Copy repo contents to Windows clipboard in pseudo XML format, or output for LLM consumption.")
    parser.add_argument(
        "-e",
        "--extensions",
        default="",
        help="Comma-separated list of file extensions to include (no dots). Example: 'py,yaml,txt'. If empty, include all",
    )
    parser.add_argument(
        "--max_size",
        type=int,
        default=50,
        help="Maximum file size in KB to include (default 50KB)",
    )
    parser.add_argument(
        "--git-ignore",
        type=lambda x: x.lower() in ['true', '1', 'yes', 'y'],
        default=True,
        help="Respect .gitignore patterns (default: True). Use '--git-ignore False' to include all files. Ignored when --llm is used (always True)",
    )
    parser.add_argument(
        "--no-ignore-common",
        action="store_true",
        help="Include common development files/directories like .venv, __pycache__, node_modules, etc. (default: ignore them)",
    )
    parser.add_argument(
        "--ignore-list",
        type=str,
        help="Path to file containing additional ignore patterns (gitignore syntax)",
    )
    parser.add_argument(
        "--only-include-list",
        type=str,
        help="Path to file containing patterns to include (gitignore syntax). Applied after gitignore filtering",
    )
    parser.add_argument(
        "--llm",
        action="store_true",
        help="LLM mode: output to stdout instead of clipboard, reduce verbose messages, force --git-ignore True",
    )
    parser.add_argument(
        "--install",
        action="store_true",
        help="Install script into ~/.local/bin and add aliases to .bashrc and Windows PowerShell",
    )
    return parser.parse_args()


def install_script(script_path: Path) -> None:
    target_dir = Path.home() / ".local" / "bin"
    target_dir.mkdir(parents=True, exist_ok=True)
    target = target_dir / script_path.name
    print(f"Copying script to {target}")
    target.write_bytes(script_path.read_bytes())
    target.chmod(target.stat().st_mode | 0o111)

    bashrc = Path.home() / ".bashrc"
    path_line = "export PATH=\"$PATH:$HOME/.local/bin\""
    if bashrc.exists():
        bash_content = bashrc.read_text()
    else:
        bash_content = ""
    if path_line not in bash_content:
        print("Adding ~/.local/bin to PATH in .bashrc")
        with bashrc.open("a") as fh:
            fh.write(f"\n# Added by repo_clipboard installer\n{path_line}\n")

    try:
        proc = subprocess.run([
            "powershell.exe",
            "-NoProfile",
            "-Command",
            "$PROFILE"
        ], capture_output=True, text=True, check=True)
        profile_path = Path(proc.stdout.strip())
        ps_content = profile_path.read_text() if profile_path.exists() else ""
        win_path = subprocess.run([
            "wslpath",
            "-w",
            str(target)
        ], capture_output=True, text=True, check=True).stdout.strip()
        alias_line = f'Set-Alias repo_clipboard "{win_path}"'
        if alias_line not in ps_content:
            print(f"Adding alias to PowerShell profile at {profile_path}")
            profile_path.parent.mkdir(parents=True, exist_ok=True)
            with profile_path.open("a") as fh:
                fh.write(f"\n# Added by repo_clipboard installer\n{alias_line}\n")
    except Exception as e:
        print(f"Failed to modify PowerShell profile: {e}")

    print("Installation complete. Restart your shells to use 'repo_clipboard'.")


def is_git_repository(path: Path) -> bool:
    """Check if the given path is inside a git repository."""
    try:
        subprocess.run(
            ["git", "rev-parse", "--git-dir"],
            capture_output=True,
            check=True,
            cwd=path,
        )
        return True
    except subprocess.CalledProcessError:
        return False


def get_git_root(path: Path) -> Path:
    """Get the root directory of the git repository."""
    result = subprocess.run(
        ["git", "rev-parse", "--show-toplevel"],
        capture_output=True,
        text=True,
        check=True,
        cwd=path,
    )
    return Path(result.stdout.strip())


def load_file_list(repo_root: Path, respect_gitignore: bool, verbose: bool = True) -> list:
    git_command = ["git", "ls-files", "-c", "-o"]
    if respect_gitignore:
        git_command.append("--exclude-standard")
        if verbose:
            print("Respecting .gitignore patterns (use --git-ignore False to include all files)")
    else:
        if verbose:
            print("Including all files (ignoring .gitignore patterns)")
    
    try:
        result = subprocess.run(
            git_command,
            capture_output=True,
            text=True,
            check=True,
            cwd=repo_root,
        )
    except subprocess.CalledProcessError as exc:
        print(f"Error running git ls-files: {exc}", file=sys.stderr)
        sys.exit(1)
    files = [repo_root / line.strip() for line in result.stdout.splitlines() if line.strip()]
    return files


def load_file_list_non_git(root_dir: Path, verbose: bool = True) -> list:
    """Load all files recursively from a non-git directory."""
    if verbose:
        print(f"Not in a git repository. Loading all files from {root_dir}")
    files = []
    for path in root_dir.rglob('*'):
        if path.is_file():
            files.append(path)
    return files


def build_tree(paths: list, repo_root: Path) -> Dict[str, Union[dict, Path]]:
    tree: Dict[str, Union[dict, Path]] = {}
    for path in paths:
        rel_parts = path.relative_to(repo_root).parts
        node = tree
        for part in rel_parts[:-1]:
            node = node.setdefault(part, {})  # type: ignore[assignment]
        node[rel_parts[-1]] = path
    return tree


def generate_xml(node: Dict[str, Union[dict, Path]], indent: int = 0) -> str:
    lines = []
    for name, child in sorted(node.items()):
        prefix = " " * indent
        if isinstance(child, dict):
            lines.append(f"{prefix}<directory name=\"{name}\">")
            lines.append(generate_xml(child, indent + 2))
            lines.append(f"{prefix}</directory>")
        else:
            try:
                content = child.read_text()
            except Exception as e:
                print(f"Could not read {child}: {e}", file=sys.stderr)
                content = ""
            lines.append(f"{prefix}<file name=\"{name}\">{content}</file>")
    return "\n".join(lines)


def get_common_ignore_patterns() -> list:
    """Get a list of common development patterns to ignore."""
    return [
        # Python virtual environments
        '.venv/', '.venv/**',
        'venv/', 'venv/**',
        'env/', 'env/**',
        
        # Python cache and compiled files
        '__pycache__/', '__pycache__/**',
        '*.pyc',
        '*.pyo',
        '*.pyd',
        
        # Python testing and coverage
        '.pytest_cache/', '.pytest_cache/**',
        '.coverage',
        'htmlcov/', 'htmlcov/**',
        'coverage/', 'coverage/**',
        '.tox/', '.tox/**',
        
        # Python build artifacts
        'dist/', 'dist/**',
        'build/', 'build/**',
        '*.egg-info/', '*.egg-info/**',
        '*.egg',
        
        # Python tools caches
        '.mypy_cache/', '.mypy_cache/**',
        '.ruff_cache/', '.ruff_cache/**',
        
        # Node.js
        'node_modules/', 'node_modules/**',
        '.npm/', '.npm/**',
        'npm-debug.log*',
        'yarn-debug.log*',
        'yarn-error.log*',
        
        # JavaScript framework caches
        '.next/', '.next/**',
        '.nuxt/', '.nuxt/**',
        
        # IDE directories
        '.idea/', '.idea/**',
        '.vscode/', '.vscode/**',
        
        # Version control (when not in git repo)
        '.git/', '.git/**',
        
        # OS files
        '.DS_Store',
        'Thumbs.db',
        
        # Editor swap files
        '*.swp',
        '*.swo',
        '*~',
        
        # Log files
        '*.log',
        
        # Environment files (often contain secrets)
        '.env',
        '.env.*',
    ]


def load_patterns_from_file(pattern_file: Path) -> list:
    """Load patterns from a file, one pattern per line, ignoring empty lines and comments."""
    if not pattern_file.exists():
        print(f"Warning: Pattern file {pattern_file} not found", file=sys.stderr)
        return []
    
    patterns = []
    with pattern_file.open('r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#'):
                patterns.append(line)
    return patterns


def apply_pathspec_filters(files: list, repo_root: Path, ignore_patterns: list, include_patterns: list) -> list:
    """Apply pathspec filters to the file list."""
    # Convert to relative paths for pathspec matching
    relative_files = [f.relative_to(repo_root) for f in files]
    
    # Apply include patterns first if specified
    if include_patterns:
        include_spec = pathspec.PathSpec.from_lines('gitwildmatch', include_patterns)
        relative_files = [f for f in relative_files if include_spec.match_file(f)]
    
    # Apply ignore patterns
    if ignore_patterns:
        ignore_spec = pathspec.PathSpec.from_lines('gitwildmatch', ignore_patterns)
        relative_files = [f for f in relative_files if not ignore_spec.match_file(f)]
    
    # Convert back to absolute paths
    return [repo_root / f for f in relative_files]


def main() -> None:
    args = parse_args()
    script_path = Path(__file__).resolve()

    if args.install:
        install_script(script_path)
        return

    # LLM mode forces git-ignore to True
    if args.llm:
        args.git_ignore = True

    # Determine if we're in a git repository
    current_dir = Path.cwd()
    is_git_repo = is_git_repository(current_dir)
    
    if is_git_repo:
        repo_root = get_git_root(current_dir)
        # Load file list with gitignore handling
        files = load_file_list(repo_root, args.git_ignore, verbose=not args.llm)
    else:
        repo_root = current_dir
        # In non-git mode, we can't respect gitignore
        if args.git_ignore and not args.llm:
            print("Warning: --git-ignore flag is ignored in non-git directories")
        files = load_file_list_non_git(repo_root, verbose=not args.llm)

    allowed_extensions = {
        ext.strip().lstrip('.')
        for ext in args.extensions.split(',') if ext.strip()
    }
    if not allowed_extensions:
        allowed_extensions = None

    max_bytes = args.max_size * 1024

    # Load patterns from files
    ignore_patterns = []
    include_patterns = []
    
    # Add common ignore patterns unless --no-ignore-common is set
    if not args.no_ignore_common:
        ignore_patterns.extend(get_common_ignore_patterns())
        if (is_git_repo or not args.git_ignore) and not args.llm:
            print("Ignoring common development files (use --no-ignore-common to include all)")
    
    if args.ignore_list:
        ignore_patterns.extend(load_patterns_from_file(Path(args.ignore_list)))
    
    if args.only_include_list:
        include_patterns.extend(load_patterns_from_file(Path(args.only_include_list)))
    
    # Apply pathspec filters
    if ignore_patterns or include_patterns:
        files = apply_pathspec_filters(files, repo_root, ignore_patterns, include_patterns)

    selected = []
    for f in files:
        if allowed_extensions is not None and f.suffix.lstrip('.') not in allowed_extensions:
            if not args.llm:
                print(f"Skipping {f} due to extension")
            continue
        try:
            size = f.stat().st_size
        except FileNotFoundError:
            continue
        if size > max_bytes:
            print(f"Skipping {f} due to size {size} bytes")
            continue
        selected.append(f)

    tree = build_tree(selected, repo_root)
    xml = generate_xml(tree)

    if args.llm:
        # LLM mode: output to stdout
        print(xml)
    else:
        # Normal mode: copy to clipboard
        try:
            subprocess.run(["clip.exe"], input=xml, text=True, check=True)
            print("Copied content to Windows clipboard using clip.exe")
        except Exception as e:
            print(f"Failed to copy using clip.exe: {e}", file=sys.stderr)
            try:
                import pyperclip  # type: ignore
                pyperclip.copy(xml)
                print("Copied content using pyperclip")
            except Exception as e2:
                print(f"Also failed to use pyperclip: {e2}", file=sys.stderr)
                sys.exit(1)

        print("Done")

    token_count = int(count_tokens(xml) * 1.2)
    if token_count > 0 and not args.llm:
        print(f"Token count: {token_count} tokens")


if __name__ == "__main__":
    main()
